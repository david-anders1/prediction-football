{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.data_preprocessor import *\n",
    "\n",
    "df = preprocess_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David.DESKTOP-UV7338N\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\prediction_football-mWxaN9Qk-py3.11\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "unable to open database file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdb_manager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_data_from_db\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_preprocessor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 4\u001b[0m df_players \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_data_from_db\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPlayers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m df_starting_xi \u001b[38;5;241m=\u001b[39m fetch_data_from_db(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStartingXI\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m df_player_stats \u001b[38;5;241m=\u001b[39m fetch_data_from_db(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlayer_Statistics\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\prediction-football\\src\\db\\db_manager.py:57\u001b[0m, in \u001b[0;36mfetch_data_from_db\u001b[1;34m(table_name)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_data_from_db\u001b[39m(table_name):\n\u001b[0;32m     44\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m    Fetch all rows from a specified table in the SQLite database and return them in a DataFrame.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m        a DataFrame containing all rows from the specified table.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msqlite3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATABASE_PATH\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[0;32m     58\u001b[0m         df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql_query(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, conn)\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[1;31mOperationalError\u001b[0m: unable to open database file"
     ]
    }
   ],
   "source": [
    "from db.db_manager import fetch_data_from_db\n",
    "from preprocessing.data_preprocessor import *\n",
    "\n",
    "df_players = fetch_data_from_db('Players')\n",
    "df_starting_xi = fetch_data_from_db('StartingXI')\n",
    "df_player_stats = fetch_data_from_db(\"Player_Statistics\")\n",
    "df_fifa_stats = fetch_data_from_db(\"FIFA_Player_Statistics\")\n",
    "\n",
    "print(df_player_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches = fetch_data_from_db('Matches')\n",
    "df_odds = fetch_data_from_db('Odds')\n",
    "df_match_statistics = fetch_data_from_db('Match_Statistics')\n",
    "\n",
    "df_merged_matches_odds = merge_match_odds(df_matches, df_odds)\n",
    "df_betting_info = add_betting_info(df_merged_matches_odds)\n",
    "df_added_winning_streak = add_winning_streak_info(df_betting_info)\n",
    "\n",
    "df_added_winning_streak['goal_difference'] = df_added_winning_streak['home_goals'] - df_added_winning_streak['away_goals']\n",
    "df_added_winning_streak['fixture_id'] = df_added_winning_streak['fixture_id'].astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_added_winning_streak.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_starting_xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_added_winning_streak['fixture_id'] = df_added_winning_streak['fixture_id'].astype('int64')\n",
    "df_starting_xi['fixture_id'] = df_starting_xi['fixture_id'].astype('int64')\n",
    "\n",
    "\n",
    "df_starting_xi['team_position'] = df_starting_xi['team'] + '_' + df_starting_xi['position_on_grid']\n",
    "df_starting_xi_grouped = df_starting_xi.groupby(['fixture_id', 'team_position'])['player_id'].agg(list).reset_index()\n",
    "df_starting_xi_pivoted = df_starting_xi_grouped.pivot(index='fixture_id', columns='team_position', values='player_id').reset_index()\n",
    "\n",
    "df_merged = pd.merge(df_added_winning_streak, df_starting_xi_pivoted, on='fixture_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of columns before the merge\n",
    "original_columns = set(df_added_winning_streak.columns)\n",
    "\n",
    "# Set of columns after the merge\n",
    "merged_columns = set(df_merged.columns)\n",
    "\n",
    "# New columns added to df_merged\n",
    "new_columns = merged_columns - original_columns\n",
    "\n",
    "# Convert to a list, if needed\n",
    "new_columns_list = list(new_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of player_id to overall_rating\n",
    "id_to_rating = df_fifa_stats.set_index('player_id')['overall_rating'].to_dict()\n",
    "\n",
    "# Define the lambda function to compute the average rating\n",
    "def average_rating(ids):\n",
    "    if isinstance(ids, list) and ids:\n",
    "        ratings = [id_to_rating.get(id, np.nan) for id in ids]\n",
    "        return np.nanmean(ratings)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the lambda function to the column\n",
    "for column in new_columns_list:\n",
    "    df_merged[column + '_rating'] = df_merged[column].apply(average_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns related to home and away\n",
    "home_cols = [col for col in df_merged.columns if 'home_' in col and '_rating' in col]\n",
    "away_cols = [col for col in df_merged.columns if 'away_' in col and '_rating' in col]\n",
    "\n",
    "# Apply aggregation\n",
    "df_merged['home_rating_aggregate'] = df_merged[home_cols].apply(np.nanmean, axis=1)  \n",
    "df_merged['away_rating_aggregate'] = df_merged[away_cols].apply(np.nanmean, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Separate the numeric columns and non-numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number])  # using numpy here\n",
    "non_numeric_cols = df.select_dtypes(exclude=[np.number])\n",
    "\n",
    "# Instantiate the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit to the data and transform it\n",
    "scaled_data = scaler.fit_transform(numeric_cols)\n",
    "\n",
    "# Creating a new dataframe with the scaled data\n",
    "scaled_numeric_cols = pd.DataFrame(scaled_data, columns=numeric_cols.columns, index=numeric_cols.index)\n",
    "\n",
    "# Concatenating the non-numeric and scaled numeric dataframes\n",
    "df_scaled = pd.concat([non_numeric_cols, scaled_numeric_cols], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('Data/football_database.db')\n",
    "\n",
    "query = \"SELECT * FROM Matches\"\n",
    "\n",
    "df_matches = pd.read_sql_query(query, conn)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('Data/football_database.db')\n",
    "\n",
    "query = \"SELECT * FROM Odds\"\n",
    "\n",
    "df_odds = pd.read_sql_query(query, conn)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_matches_odds = df_matches.merge(df_odds[['fixture_id', 'home_odds', 'draw_odds', 'away_odds']], on='fixture_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_matches_odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function that returns the favorite team (with the best odds)\n",
    "def get_favorite(row):\n",
    "    if row['home_odds'] < row['away_odds']:\n",
    "        return 'home'\n",
    "    else:\n",
    "        return 'away'\n",
    "    \n",
    "# Function that returns the underdog team (with the worst odds)\n",
    "def get_underdog(row):\n",
    "    if row['home_odds'] > row['away_odds']:\n",
    "        return 'home'\n",
    "    else:\n",
    "        return 'away'\n",
    "    \n",
    "# Function that calculates the result of the game\n",
    "def get_result(row):\n",
    "    if row['home_goals'] > row['away_goals']:\n",
    "        return 'home'  # home team won\n",
    "    elif row['home_goals'] < row['away_goals']:\n",
    "        return 'away'  # away team won\n",
    "    else:\n",
    "        return 'draw'  # draw\n",
    "\n",
    "def calculate_margin(row, bet_target, bet_amount = 10):\n",
    "    try:\n",
    "        if bet_target == 'draw':\n",
    "            if row['result'] == 'X':\n",
    "                return bet_amount * float(row['draw_odds']) - bet_amount  # win, so return profit\n",
    "            else:\n",
    "                return -bet_amount  # loss, so return loss\n",
    "        elif bet_target == 'favorite':\n",
    "            odds = row['home_odds'] if row['favorite'] == 'home' else row['away_odds']\n",
    "            if row['favorite'] == row['result']:\n",
    "                return bet_amount * float(odds) - bet_amount  # win, so return profit\n",
    "            else:\n",
    "                return -bet_amount  # loss, so return loss\n",
    "        else:  # bet_target is 'underdog'\n",
    "            odds = row['home_odds'] if row['underdog'] == 'home' else row['away_odds']\n",
    "            if row['underdog'] == row['result']:\n",
    "                return bet_amount * float(odds) - bet_amount  # win, so return profit\n",
    "            else:\n",
    "                return -bet_amount  # loss, so return loss\n",
    "    except ValueError as e:\n",
    "        return None\n",
    "\n",
    "def add_betting_info(df):\n",
    "    df = df.copy()  # make a copy of the dataframe to avoid changing the original dataframe\n",
    "    df['favorite'] = df.apply(get_favorite, axis=1)\n",
    "    df['underdog'] = df.apply(get_underdog, axis=1)\n",
    "    df['result'] = df.apply(get_result, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def bet_on(df, bet_target, bet_amount = 10):\n",
    "    df['win_margin_bet_on_'+bet_target] = df.apply(calculate_margin, args=(bet_target, bet_amount), axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_matches_odds = add_betting_info(df_merged_matches_odds)\n",
    "df_joined = bet_on(df_merged_matches_odds, bet_target='favorite', bet_amount=10)  # bet on favorite\n",
    "df_joined = bet_on(df_merged_matches_odds, bet_target='underdog', bet_amount=10)  # bet on underdog\n",
    "df_joined = bet_on(df_merged_matches_odds, bet_target='draw', bet_amount=10)  # bet on draw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_win_margin_favorite = df_joined['win_margin_bet_on_favorite'].sum()\n",
    "total_win_margin_underdog = df_joined['win_margin_bet_on_underdog'].sum()\n",
    "total_win_margin_draw = df_joined['win_margin_bet_on_draw'].sum()\n",
    "print(total_win_margin_favorite, total_win_margin_underdog, total_win_margin_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('Data/football_database.db')\n",
    "\n",
    "query = \"SELECT * FROM Match_Statistics\"\n",
    "df_match_statistics = pd.read_sql_query(query, conn)\n",
    "\n",
    "query = \"SELECT * FROM Players\"\n",
    "df_players = pd.read_sql_query(query, conn)\n",
    "\n",
    "query = \"SELECT * FROM Player_Statistics\"\n",
    "df_player_statistics = pd.read_sql_query(query, conn)\n",
    "\n",
    "query = \"SELECT * FROM StartingXI\"\n",
    "df_starting_xi = pd.read_sql_query(query, conn)\n",
    "\n",
    "query = \"SELECT * FROM Substitutes\"\n",
    "df_substitutes = pd.read_sql_query(query, conn)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries to store the streaks and seasons (to reset streak on new season start)\n",
    "home_streaks = {}\n",
    "away_streaks = {}\n",
    "home_seasons = {}\n",
    "away_seasons = {}\n",
    "\n",
    "def calculate_winning_streak(df):\n",
    "    # Convert 'match_date' to datetime\n",
    "    df['match_date'] = pd.to_datetime(df['match_date'], format='%d.%m.%Y')\n",
    "    df = df.sort_values('match_date')\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        home_team = row['home_team']\n",
    "        away_team = row['away_team']\n",
    "        result = row['result']\n",
    "        season = row['season']\n",
    "        \n",
    "        # Check if the teams have played before, if not set their streaks to 0\n",
    "        home_streaks.setdefault(home_team, 0)\n",
    "        away_streaks.setdefault(away_team, 0)\n",
    "        home_seasons.setdefault(home_team, season)\n",
    "        away_seasons.setdefault(away_team, season)\n",
    "\n",
    "        # Reset the streak if the season has changed\n",
    "        if home_seasons[home_team] != season:\n",
    "            home_streaks[home_team] = 0\n",
    "            home_seasons[home_team] = season\n",
    "        if away_seasons[away_team] != season:\n",
    "            away_streaks[away_team] = 0\n",
    "            away_seasons[away_team] = season\n",
    "\n",
    "        # Store the streaks in the DataFrame\n",
    "        df.at[i, 'home_winning_streak'] = home_streaks[home_team]\n",
    "        df.at[i, 'away_winning_streak'] = away_streaks[away_team]\n",
    "\n",
    "        # Update the streaks based on the game result\n",
    "        # If the home team won, increase their streak and reset the away team's streak\n",
    "        if result == 'home':\n",
    "            home_streaks[home_team] += 1\n",
    "            away_streaks[away_team] = 0\n",
    "        # If the away team won, increase their streak and reset the home team's streak\n",
    "        elif result == 'away':\n",
    "            away_streaks[away_team] += 1\n",
    "            home_streaks[home_team] = 0\n",
    "        # If it was a draw, reset both team's streaks\n",
    "        else:\n",
    "            home_streaks[home_team] = 0\n",
    "            away_streaks[away_team] = 0\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = calculate_winning_streak(df_joined)\n",
    "df_sorted.reset_index(inplace=True, drop=True)\n",
    "df_sorted['goal_difference'] = df_sorted['home_goals'] - df_sorted['away_goals']\n",
    "df_sorted.to_csv(\"test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted['fixture_id'] = df_sorted['fixture_id'].astype('int64')\n",
    "\n",
    "# drop season 2010 in data cleaning\n",
    "df_match_merged_stats = df_sorted.merge(df_match_statistics, on=\"fixture_id\")\n",
    "\n",
    "print(df_match_merged_stats.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert '-' to NaN, then drop these rows\n",
    "df = df_match_merged_stats.replace('-', np.nan)\n",
    "df = df.dropna(subset=['home_odds', 'draw_odds', 'away_odds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the column \"expected goals\"\n",
    "index_of_column = df.columns.get_loc(\"home_expected_goals\")\n",
    "\n",
    "# Slice the DataFrame up to this column\n",
    "df = df.iloc[:, :index_of_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_stats = [\n",
    "    \"home_fouls\", \"home_corner_kicks\", \"home_offsides\", \"home_ball_possession\", \n",
    "    \"home_yellow_cards\", \"home_red_cards\", \"home_goalkeeper_saves\", \n",
    "    \"home_total_passes\", \"home_passes_accurate\", \"home_passes_percent\"\n",
    "]\n",
    "\n",
    "away_stats = [\n",
    "    \"away_fouls\", \"away_corner_kicks\", \"away_offsides\", \"away_ball_possession\", \n",
    "    \"away_yellow_cards\", \"away_red_cards\", \"away_goalkeeper_saves\", \n",
    "    \"away_total_passes\", \"away_passes_accurate\", \"away_passes_percent\"\n",
    "]\n",
    "\n",
    "n_rolling_average = 5  \n",
    "\n",
    "# First, we need to create a unified dataset for both home and away games\n",
    "home_df = df[['home_team', 'match_date'] + home_stats].rename(columns={'home_team': 'team', **{stat: stat.replace('home_', '') for stat in home_stats}})\n",
    "away_df = df[['away_team', 'match_date'] + away_stats].rename(columns={'away_team': 'team', **{stat: stat.replace('away_', '') for stat in away_stats}})\n",
    "# To keep track of the home and away team (useful for merging the stats later on again)\n",
    "home_df['type'] = 'home'\n",
    "away_df['type'] = 'away'\n",
    "\n",
    "all_teams_df = pd.concat([home_df, away_df], axis=0).sort_values(by=['team', 'match_date'])\n",
    "all_teams_df = all_teams_df.reset_index(drop=True)\n",
    "numeric_cols = [col for col in all_teams_df.columns if all_teams_df[col].dtype != 'datetime64[ns]' and col not in ['team', 'type']]\n",
    "\n",
    "def rolling_avg(group):\n",
    "    group[numeric_cols] = group[numeric_cols].rolling(window=n_rolling_average, min_periods=1, closed=\"left\").mean()\n",
    "    return group\n",
    "\n",
    "# Now compute the rolling average for this unified dataset\n",
    "all_teams_df_grouped = all_teams_df.groupby('team').apply(rolling_avg).reset_index(drop=True)\n",
    "\n",
    "home_stats_df = all_teams_df_grouped[all_teams_df_grouped['type'] == 'home'].copy()\n",
    "away_stats_df = all_teams_df_grouped[all_teams_df_grouped['type'] == 'away'].copy()\n",
    "\n",
    "# Renaming columns in home_stats_df\n",
    "home_cols_to_rename = {col: 'home_avg_' + col for col in home_stats_df.columns if col not in ['team', 'match_date', 'type']}\n",
    "home_stats_df.rename(columns=home_cols_to_rename, inplace=True)\n",
    "\n",
    "# Renaming columns in away_stats_df\n",
    "away_cols_to_rename = {col: 'away_avg_' + col for col in away_stats_df.columns if col not in ['team', 'match_date', 'type']}\n",
    "away_stats_df.rename(columns=away_cols_to_rename, inplace=True)\n",
    "\n",
    "# Merging with the original dataframe\n",
    "df_with_form_stats = df.merge(home_stats_df, left_on=['home_team', 'match_date'], right_on=['team', 'match_date'], how='left').drop(columns=['team', 'type'])\n",
    "df_with_form_stats = df_with_form_stats.merge(away_stats_df, left_on=['away_team', 'match_date'], right_on=['team', 'match_date'], how='left').drop(columns=['team', 'type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count NaN values\n",
    "nan_count = df['away_rating_aggregate'].isna().sum()\n",
    "\n",
    "# Calculate percentage\n",
    "nan_percentage = (nan_count / len(df)) * 100\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total NaN values in column: {nan_count}\")\n",
    "print(f\"Percentage of NaN values: {nan_percentage:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Specify the features and target variable\n",
    "target_feature = \"result\"\n",
    "features = ['home_winning_streak', 'away_winning_streak', 'home_odds', 'draw_odds', 'away_odds', 'home_rating_aggregate', 'away_rating_aggregate']\n",
    "\n",
    "# Additional rolling average stats\n",
    "rolling_avg_features = [\n",
    "    \"home_avg_fouls\", \"home_avg_corner_kicks\", \"home_avg_offsides\", \"home_avg_ball_possession\",\n",
    "    \"home_avg_yellow_cards\", \"home_avg_red_cards\", \"home_avg_goalkeeper_saves\",\n",
    "    \"home_avg_total_passes\", \"home_avg_passes_accurate\", \"home_avg_passes_percent\",\n",
    "    \n",
    "    \"away_avg_fouls\", \"away_avg_corner_kicks\", \"away_avg_offsides\", \"away_avg_ball_possession\",\n",
    "    \"away_avg_yellow_cards\", \"away_avg_red_cards\", \"away_avg_goalkeeper_saves\",\n",
    "    \"away_avg_total_passes\", \"away_avg_passes_accurate\", \"away_avg_passes_percent\"\n",
    "]\n",
    "\n",
    "features += rolling_avg_features\n",
    "#df = df_merged\n",
    "df = df.dropna(subset=features)\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target_feature], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the models\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "models = [lr, dt, rf]\n",
    "\n",
    "# Iterate over models\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    acc_train = accuracy_score(y_train, y_pred_train)\n",
    "    acc_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"Training Accuracy: {acc_train}\")\n",
    "    print(f\"Test Accuracy: {acc_test}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target labels\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_test_encoded = encoder.transform(y_test)\n",
    "\n",
    "# Define a simple neural network model using Keras\n",
    "model_nn = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(len(encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_nn.compile(optimizer=Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_nn.fit(X_train, y_train_encoded, epochs=20, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss, train_acc = model_nn.evaluate(X_train, y_train_encoded, verbose=0)\n",
    "test_loss, test_acc = model_nn.evaluate(X_test, y_test_encoded, verbose=0)\n",
    "\n",
    "print(f\"Neural Network:\")\n",
    "print(f\"Training Accuracy: {train_acc}\")\n",
    "print(f\"Test Accuracy: {test_acc}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_columns = ['home_odds', 'draw_odds', 'away_odds']\n",
    "\n",
    "\n",
    "def format_result(x):\n",
    "    if(x == \"home\"):\n",
    "        return 0\n",
    "    elif(x == \"draw\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# Convert odds to implied probabilities\n",
    "implied_probabilities = 1 / df[odds_columns]\n",
    "actual_outcomes = df['result'].apply(lambda x: format_result(x))  # assuming 0: home win, 1: draw, 2: away win\n",
    "predicted_probabilities = lr.predict_proba(X_test)\n",
    "\n",
    "# Simulate betting\n",
    "stake = 10\n",
    "profit = 0\n",
    "count = 0\n",
    "\n",
    "for idx, (actual, probs) in enumerate(zip(actual_outcomes, predicted_probabilities)):\n",
    "    # Find the most probable bet according to the model\n",
    "    best_bet = np.argmax(probs)\n",
    "    if probs[best_bet] > implied_probabilities.iloc[idx, best_bet]:  # Model believes it's a value bet\n",
    "        # Simulate placing the bet\n",
    "        if best_bet == actual:\n",
    "            profit += stake * df.iloc[idx].loc[odds_columns[best_bet]] - stake  # Winning bet\n",
    "        else:\n",
    "            profit -= stake  # Losing bet\n",
    "            \n",
    "print(f\"Total Profit: ${profit}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction_football-mWxaN9Qk-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
